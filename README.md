# FACE IMAGE ENHANCEMENT AND RESTORATION

<p align="center">
  <img src="https://img.shields.io/badge/PYTHON-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/PYTORCH-2.0%2B-red?style=for-the-badge&logo=pytorch&logoColor=white" />
  <img src="https://img.shields.io/badge/OPENCV-COMPUTER%20VISION-green?style=for-the-badge&logo=opencv&logoColor=white" />
  <img src="https://img.shields.io/badge/GFPGAN-RESTORATION-orange?style=for-the-badge" />
  <br>
  <img src="https://img.shields.io/github/last-commit/DaRkSouL36/FACE-IMAGE-ENHANCEMENT-AND-RESTORATION?style=for-the-badge&color=blueviolet" />
  <img src="https://img.shields.io/github/repo-size/DaRkSouL36/FACE-IMAGE-ENHANCEMENT-AND-RESTORATION?style=for-the-badge&color=blue" />
  <img src="https://img.shields.io/github/languages/count/DaRkSouL36/FACE-IMAGE-ENHANCEMENT-AND-RESTORATION?style=for-the-badge&color=green" />
  <img src="https://img.shields.io/github/languages/top/DaRkSouL36/FACE-IMAGE-ENHANCEMENT-AND-RESTORATION?style=for-the-badge&color=orange" />
  <img src="https://img.shields.io/badge/LICENSE-MIT-yellow?style=for-the-badge" />
  <br><br>
</p>

<h1 align="center">RESTORING IDENTITY. PIXEL BY PIXEL.</h1>

> <p align="center"><b>A STATE-OF-THE-ART DEEP LEARNING PIPELINE FOR BLIND FACE RESTORATION AND SUPER-RESOLUTION.</b></p>
> <p align="center"><b>ALIGN. DETECT. RESTORE. ENHANCE. VERIFY.</b></p>

<div style="text-align: justify;">
THIS PROJECT IMPLEMENTS A ROBUST IMAGE ENHANCEMENT SYSTEM DESIGNED TO RECOVER HIGH-FIDELITY FACE DETAILS FROM SEVERELY DEGRADED INPUTS (LOW RESOLUTION, NOISE, THERMAL COLOR CASTS). BY LEVERAGING GENERATIVE FACIAL PRIORS (GFPGAN) AND REAL-WORLD SUPER-RESOLUTION (REAL-ESRGAN), IT RECONSTRUCTS FACIAL GEOMETRY WHILE PRESERVING IDENTITY. THE PIPELINE INCLUDES RIGOROUS PRE-PROCESSING, STAGE-WISE RESTORATION, AND QUANTITATIVE VALIDATION USING PERCEPTUAL METRICS.
</div>

---

## ðŸ“– TABLE OF CONTENTS

- [FACE IMAGE ENHANCEMENT AND RESTORATION](#face-image-enhancement-and-restoration)
  - [ðŸ“– TABLE OF CONTENTS](#-table-of-contents)
  - [ðŸ“˜ PROJECT OVERVIEW](#-project-overview)
  - [ðŸ“‚ DIRECTORY STRUCTURE](#-directory-structure)
  - [ðŸ’¬ FEATURES](#-features)
  - [âš™ï¸ THE PIPELINE ARCHITECTURE](#ï¸-the-pipeline-architecture)
  - [ðŸ§  MATHEMATICAL FOUNDATIONS](#-mathematical-foundations)
    - [1. GENERATIVE ADVERSARIAL LOSS](#1-generative-adversarial-loss)
    - [2. IDENTITY PRESERVATION (COSINE SIMILARITY)](#2-identity-preservation-cosine-similarity)
    - [3. PERCEPTUAL LOSS (LPIPS)](#3-perceptual-loss-lpips)
  - [ðŸ“Š MODELS \& DEPENDENCIES](#-models--dependencies)
  - [ðŸ“ EVALUATION METRICS](#-evaluation-metrics)
  - [ðŸ“¸ VISUALIZATION STANDARDS](#-visualization-standards)
  - [ðŸ“ˆ RESULTS \& BENCHMARKS](#-results--benchmarks)
  - [âœ” KEY OBSERVATIONS](#-key-observations)
  - [âš ï¸ LIMITATIONS](#ï¸-limitations)
  - [ðŸš€ FUTURE WORK](#-future-work)
  - [ðŸ“„ LICENSE](#-license)
  - [ðŸ“¦ INSTALLATION INSTRUCTIONS](#-installation-instructions)
    - [`PREREQUISITES`: PYTHON 3.10+, CUDA-CAPABLE GPU (RECOMMENDED)](#prerequisites-python-310-cuda-capable-gpu-recommended)

---

## ðŸ“˜ PROJECT OVERVIEW

IN REAL-WORLD SCENARIOS, FACE IMAGES ARE OFTEN DEGRADED BY MOTION BLUR, POOR LIGHTING, OR SENSOR NOISE. TRADITIONAL FILTERS FAIL TO RECOVER SEMANTIC DETAILS LIKE EYES OR SKIN TEXTURE.

THIS PROJECT SOLVES **BLIND FACE RESTORATION** BY COMBINING:

1.  **GEOMETRIC ALIGNMENT:** USING FACIAL LANDMARKS TO STANDARDIZE INPUT.
2.  **GENERATIVE PRIORS:** USING A PRE-TRAINED GAN (STYLEGAN2) TO "HALLUCINATE" MISSING HIGH-FREQUENCY DETAILS.
3.  **BACKGROUND UPSAMPLING:** ENSURING THE NON-FACE REGIONS ARE EQUALLY SHARP.
4.  **IDENTITY VERIFICATION:** ENSURING THE RESTORED FACE IS MATHEMATICALLY SIMILAR TO THE INPUT.
5.  **MODULARITY:** A PLUG-AND-PLAY ARCHITECTURE WHERE MODULES CAN BE SWAPPED OR EXTENDED.

---

## ðŸ“‚ DIRECTORY STRUCTURE

THE PROJECT FOLLOWS A STRICT, MODULAR ORGANIZATION TO SEPARATE DOCUMENTATION, LICENSING, AND DEPENDENCIES.

- **LICENSE** â€“ MIT LICENSE FOR THE PROJECT.
- **REQUIREMENTS.txt** â€“ LIST OF PYTHON DEPENDENCIES REQUIRED TO RUN THE PIPELINE.
- **WORKSHOP/** â€“ CONTAINS HANDS-ON MATERIALS INCLUDING NOTEBOOK AND DATA.
  - **NOTEBOOK.ipynb** â€“ MAIN NOTEBOOK DEMONSTRATING THE COMPLETE FACE RESTORATION PIPELINE.
  - **DATA/** â€“ SAMPLE INPUT IMAGES AND DATASETS USED FOR TESTING AND DEMONSTRATION.

- **DOCS/** â€“ PROJECT DOCUMENTATION AND TECHNICAL DETAILS.
  - **ENVIRONMENT_SETUP.md** â€“ INSTALLATION GUIDE AND GPU/CUDA CONFIGURATION.
  - **FACE_IMAGE_RESTORATION_PIPELINE.md** â€“ DETAILED PIPELINE ARCHITECTURE AND WORKFLOW.
  - **MODEL_DETAILS.md** â€“ DESCRIPTION AND SPECIFICATIONS OF ALL MODELS USED.

---

## ðŸ’¬ FEATURES

- **ADAPTIVE PRE-PROCESSING:** AUTOMATIC WHITE BALANCE (GRAY WORLD) AND NON-LOCAL MEANS DENOISING.
- **BLIND RESTORATION:** RECOVERS FACES WITHOUT NEEDING A "GROUND TRUTH" REFERENCE PAIR.
- **IDENTITY PRESERVATION:** INTEGRATED `INSIGHTFACE` VERIFICATION TO PREVENT IDENTITY DRIFT.
- **ARTIFACT REMOVAL:** ELIMINATES JPEG COMPRESSION ARTIFACTS AND SENSOR GRAIN.
- **SCIENTIFIC VALIDATION:** CALCULATES PSNR, SSIM, AND LPIPS FOR EVERY OUTPUT.

---

## âš™ï¸ THE PIPELINE ARCHITECTURE

THE SYSTEM FOLLOWS A STRICT MODULAR FLOW WHERE NO MODULE MAY MODIFY GLOBAL STATE.

`LOW-QUALITY INPUT` âžœ [FACE DETECTION & ALIGNMENT] âžœ [DENOISING] âžœ [SEMANTIC RESTORATION] âžœ [SUPER-RESOLUTION] âžœ [COLOR ENHANCEMENT] âžœ `HIGH-RES OUTPUT`

> DATA FLOW CONTRACT

- INPUT: NUMPY ARRAY `(H Ã— W Ã— C)`, RGB, FLOAT32
- OUTPUT: NUMPY ARRAY `(H Ã— W Ã— C)`, RGB, FLOAT32

> THE SYSTEM FOLLOWS A STRICT MODULAR FLOW:

1.  **DATA INGESTION:** LOADS IMAGE AND CONVERTS TO RGB (FLOAT32).
2.  **COLOR CORRECTION:** APPLIES CLAHE AND WHITE BALANCE TO REMOVE COLOR CASTS (E.G., THERMAL BLUE).
3.  **DENOISING:** APPLIES `cv2.fastNlMeansDenoisingColored` TO CLEAN SENSOR NOISE.
4.  **ALIGNMENT:** DETECTS 5 FACIAL LANDMARKS AND WARPS THE FACE TO A CANONICAL VIEW.
5.  **RESTORATION (GFPGAN):** INJECTS LATENT CODES INTO A GENERATIVE DECODER.
6.  **FUSION:** PASTES THE ENHANCED FACE BACK INTO THE UPSCALED BACKGROUND (REAL-ESRGAN).
7.  **VALIDATION:** COMPUTES SIMILARITY METRICS BETWEEN INPUT AND OUTPUT.

---

## ðŸ§  MATHEMATICAL FOUNDATIONS

### 1. GENERATIVE ADVERSARIAL LOSS

THE NETWORK OPTIMIZES A MIN-MAX GAME TO GENERATE REALISTIC TEXTURES:

$$L_{adv} = \mathbb{E}_{x}[\log D(x)] + \mathbb{E}_{z}[\log(1 - D(G(z)))]$$

### 2. IDENTITY PRESERVATION (COSINE SIMILARITY)

WE PROJECT FACES INTO A 512-D EMBEDDING SPACE USING ARCFACE. THE SIMILARITY SCORE $S$ IS:

$$S(u, v) = \frac{u \cdot v}{\|u\| \|v\|}$$

WHERE $u$ IS THE INPUT EMBEDDING AND $v$ IS THE RESTORED EMBEDDING.

### 3. PERCEPTUAL LOSS (LPIPS)

INSTEAD OF PIXEL DIFFERENCE (MSE), WE MEASURE DISTANCE IN FEATURE SPACE (ALEXNET LAYERS):

$$d(x, x_0) = \sum_l \frac{1}{H_l W_l} \sum_{h,w} \| w_l \odot (\hat{y}^l_{hw} - \hat{y}^l_{0,hw}) \|_2^2$$

---

## ðŸ“Š MODELS & DEPENDENCIES

| COMPONENT            | MODEL ARCHITECTURE    | PURPOSE                              |
| :------------------- | :-------------------- | :----------------------------------- |
| **FACE RESTORATION** | GFPGAN (V1.3 CLEAN)   | RECOVERING FACIAL GEOMETRY & TEXTURE |
| **UPSAMPLER**        | REAL-ESRGAN (X4 PLUS) | ENHANCING BACKGROUND RESOLUTION      |
| **DETECTION**        | RETINAFACE (RESNET50) | LOCATING FACES & LANDMARKS           |
| **IDENTITY CHECK**   | ARCFACE (BUFFALO_L)   | EXTRACTING DEEP EMBEDDINGS           |
| **METRICS**          | ALEXNET (LPIPS)       | CALCULATING PERCEPTUAL QUALITY       |

---

## ðŸ“ EVALUATION METRICS

WE DO NOT RELY SOLELY ON VISUAL INSPECTION. EVERY RESTORATION IS SCORED ON:

- **PSNR (PEAK SIGNAL-TO-NOISE RATIO):** MEASURES PIXEL FIDELITY (TARGET > 25dB).
- **SSIM (STRUCTURAL SIMILARITY):** MEASURES STRUCTURE PRESERVATION (TARGET > 0.8).
- **LPIPS (PERCEPTUAL SIMILARITY):** MEASURES HUMAN-PERCEIVED QUALITY (TARGET < 0.3).
- **IDENTITY SCORE:** COSINE SIMILARITY OF EMBEDDINGS (TARGET > 0.4).

---

## ðŸ“¸ VISUALIZATION STANDARDS

ALL OUTPUTS GENERATED BY THIS PIPELINE ADHERE TO STRICT VISUAL GUIDELINES FOR ACADEMIC PRESENTATION:

- **DPI:** 500 (PUBLICATION QUALITY)
- **GRID:** ENABLED FOR SPATIAL REFERENCE
- **LABELS:** BOLD, UPPERCASE AXIS AND TITLES
- **COLOR SPACE:** CORRECTED RGB

---

## ðŸ“ˆ RESULTS & BENCHMARKS

<div style="text-align: justify;">
IN INTERNAL TESTING ON DEGRADED THERMAL SAMPLES, THE PIPELINE ACHIEVED:

- **PSNR:** ~35.77 dB (EXCEPTIONALLY HIGH FIDELITY)
- **SSIM:** ~0.95 (NEAR-PERFECT STRUCTURAL RETENTION)
- **IDENTITY CHECK:** PASSED (CONFIDENCE > THRESHOLD)

THE SYSTEM SUCCESSFULLY REMOVED HEAVY BLUE TINTS AND SENSOR NOISE WHILE RECONSTRUCTING REALISTIC EYES AND SKIN PORES. THE PIPELINE TRANSFORMS DEGRADED SIGNALS INTO RESTORED OUTPUTS WHILE MAINTAINING STRICT VISUALIZATION STANDARDS.

**INPUT (DEGRADED)**

---

`CHARACTERISTICS`

- THERMAL BLUE CAST
- LOW RESOLUTION
- BLURRY FACIAL FEATURES.

**OUTPUT (RESTORED)**

---

`IMPROVEMENTS`

- CORRECTED COLOR BALANCE.
- RECOVERED EYES, NOSE, AND MOUTH GEOMETRY.
- INCREASED RESOLUTION (UPSCALED).
- REMOVED SENSOR NOISE.
</div>

---

## âœ” KEY OBSERVATIONS

BASED ON EXTENSIVE TESTING AND MODEL CONFIGURATION:

- **REALISM OVER SHARPNESS**: THE SYSTEM PRIORITIZES NATURAL TEXTURE OVER ARTIFICIAL SHARPNESS TO AVOID "CARTOONISH" RESULTS.

- **IDENTITY CONSTRAINTS**: IF THE RESTORATION DRIFTS TOO FAR FROM THE ORIGINAL IDENTITY (LOW COSINE SIMILARITY), THE SYSTEM CAN FLAG THE RESULT FOR REVIEW.

- **MODULARITY WINS**: THE DECOUPLED ARCHITECTURE ALLOWS SWAPPING REAL-ESRGAN FOR OTHER UPSCALERS WITHOUT BREAKING THE RESTORATION MODULE.

- **THERMAL CORRECTION**: THE PRE-PROCESSING STAGE EFFECTIVELY NEUTRALIZES COLOR CASTS (LIKE THE BLUE TINT IN THERMAL/NIGHT-VISION INPUTS) BEFORE THE GAN SEES THE IMAGE.

---

## âš ï¸ LIMITATIONS

- EXTREME SIDE PROFILES
- HEAVY OCCLUSION
- MULTIPLE FACES IN A SINGLE IMAGE
- EXTREMELY LOW-INFORMATION INPUTS
- THESE ARE INHERENT LIMITATIONS OF CURRENT FACE RESTORATION MODELS.

---

## ðŸš€ FUTURE WORK

- `VIDEO SUPPORT`: EXTEND PIPELINE TO HANDLE TEMPORAL CONSISTENCY IN VIDEO STREAMS.
- `CUSTOM TRAINING`: FINE-TUNE GFPGAN ON SPECIFIC DOMAIN DATASETS (E.G., VINTAGE PHOTOS).
- `WEB INTERFACE`: DEPLOY THE MODEL USING FASTAPI AND REACT FOR USER INTERACTION (IN PROGRESS).
- `LOCALIZATION`: ADD SUPPORT FOR EXTREME POSE ANGLES (>90 DEGREES).

---

---

## ðŸ“„ LICENSE

THIS PROJECT IS LICENSED UNDER THE [MIT LICENSE](LICENSE).

YOU ARE FREE TO USE, MODIFY, AND DISTRIBUTE THIS PROJECT WITH ATTRIBUTION.

---

## ðŸ“¦ INSTALLATION INSTRUCTIONS

### `PREREQUISITES`: PYTHON 3.10+, CUDA-CAPABLE GPU (RECOMMENDED)

> 1. **CLONE THE REPOSITORY**

---

`git clone https://github.com/DaRkSouL36/FACE-IMAGE-ENHANCEMENT-AND-RESTORATION`

`cd "FACE-IMAGE-ENHANCEMENT-AND-RESTORATION"`

---

> 2. **CREATE VIRTUAL ENVIRONMENT**

---

`python -m venv VENV`

- LINUX/MAC

  `source VENV/bin/activate`

- ON WINDOWS

  `VENV\Scripts\activate`

---

> 3. **INSTALL DEPENDENCIES**

---

`pip install -r REQUIREMENTS.txt`

- ENSURE YOU HAVE PYTORCH INSTALLED WITH CUDA SUPPORT IF AVAILABLE

---

<p>
  <a href="#face-image-enhancement-and-restoration">
    <img src="https://img.icons8.com/fluency/48/up.png" width="20px"/>
    <strong>RETURN</strong>
  </a>
</p>
